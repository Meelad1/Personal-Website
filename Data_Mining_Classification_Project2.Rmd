---
title: "Data_Mining_Classification_Project"
author: "Meelad Doroodchi"
date: "2023-10-01"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Dataset Overview 

Link to my dataset: https://www.kaggle.com/datasets/fedesoriano/heart-failure-predictionLinks to an external site.

The dataset I have chosen for this classification project is called "Heart Failure Prediction Dataset", I chose this because in classification models you need to be able to do something that you can predict with and as well as that health in data mining is really important and key to getting an understanding of health pre-cautions people need to take! 

The data set consists of 5 individual data sets compiled from the UCI machine learning repository onto kaggle. The data contains global heart disease diagnosis from the following countries:

Cleveland: 303 observations
Hungarian: 294 observations
Switzerland: 123 observations
Long Beach CA: 200 observations
Stalag, Germany Heart Data Set: 270 observations
Feature Specifics: 

12 features
ChestPainType (TA, ATA, NAP, ASY)
ST_Slope (Measured by ECG during exercise, up (heart attack )or down(reduced blood flow to heart))
Oldpeak (Measured by an ECG, may show Q wave)
ExerciseAngina(Exercise induced pain, caused by blocked coronary arteries)
HeartDisease (response variable of heart disease diagnosis)

Data Significance: 

Heart Disease refers to a variety of problems related to Atherosclerosis which is a condition where plaque narrows the arteries, making it harder for blood to flow through. If a blood clot forms it can cause a heart attack or stroke.

Significance 

Cardiovascular diseases (CVDâ€™s)  are the number one cause of death globally with 17.9 million deaths/year*.  Just over 4 out of 5 CVD deaths are caused by heart attack and stroke alone.

Motivation

Healthy behavioral habits have been shown to significantly reduce the risk of cardiovascular disease. Creation of accurate machine learning models and clear communication of them could help people change behavioral habits and promote heart health. 

Something that I will do first is change the "ExcerciseAngina" since it was a binary outcome I want to encode this with zeroes (for "N") and ones (for "Y") for storage and optimization purposes. 


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:


#Import libraries 
```{r}
library(tidyverse)
library(dplyr)
library(GGally)
library(class)
library(bestglm)
library(rpart)
library(rpart.plot)
library(vip)
library(MASS)
library(caret)
library(recipes)
```

# Look at Data Structure 
```{r}
heart4 <- read.csv("heart1.csv")
```



```{r}
heart4 <- na.omit(heart1)
dim(heart4)
```
# The data had no NA observations and it appears that R is encoding all the variables with the right types. Since the outcome variable is going to be "HeartDisease" and R is encoding it as an integer, that will work for K nearest neighbors however for logistic regression where I am predicting probability outcomes I will have to change it to a factor so I will have to keep that in mind.
# One feature type I wanted to change was the "ExcerciseAngina" since it was a binary outcome I wanted to encode this with zeroes (for "N") and ones (for "Y") for storage and optimization purposes.


```{r}
heart <- heart4 %>%
  mutate(ExerciseAngina = case_when(
    ExerciseAngina == "Y" ~ 1,
    ExerciseAngina == "N" ~ 0)
    )
```


```{r}
heart$ExerciseAngina <- as.integer(heart$ExerciseAngina)
```


```{r}
str(heart)
```
The data contains no missing observations, has all correct types for the features and is ready to begin further explorations.

# Questions of Interest

1. What variables or combination of variables are significant in creating a classification model for heart disease?

2. What classification models can I use to minimize false negatives? (an important consideration for diagnosing heart disease)

# Exploring the Data
```{r, message = FALSE}
ggpairs(heart, columns=c(1,4,5,8,9),
        ggplot2::aes(colour = as.factor(HeartDisease)))
```
# After looking at the plot I observed a couple interesting trends in the ggpairs plot.

  1. Cholesterol rates for individuals with a CVD were bimodal and had a wider spread.
  2. Max HR seemed to have 2 subgroups based on CVD diagnosis.
  3. Exercise Angina seemed to be a great indicator of a CVD  diagnosis.
  
# Identifying features:
  **Outcome:** HeartDisease - This is the outcome variable of either "0" for a person diagnosed with no heart disease     or a "1" indicating that person was diagnosed by a doctor with a form of heart disease.

  **Numeric Feature:** MaxHR - Numeric feature of the maximum heart rate (bpm) that a person achieved at the time of    examination.

  **Categorical Feature:** ExcerciseAngina - This is a categorical feature that was determined at the time of             examination with either a "1" indicating the patient had Angina from exercise or "0" indicating the patient did       not have it. Exercise Angina is a condition where a patient experiences chest neck or jaw pain after or during a      workout indicating a person's blood flow cannot be maintained at high enough levels. this is usually due to           cholesterol-clogged coronary arteries.
  
  
# Scaling the Numeric Feature

### For KNN I want to add a MaxHRNorm that is scaled:


```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) }

heart$MaxHRNorm <- normalize(heart$MaxHR)
min(heart$MaxHRNorm)
max(heart$MaxHRNorm)
```

The explanatory feature MaxHR is now normalized. Now, I am not using all the features in my KNN model only two. So I am going to create a new dataframe that contains only the outcome "HeartDisease", the numeric explanantory "MaxHRNorm", and the categorical feature "ExcerciseAngina" which needs to be encoded as a factor.
```{r, message = FALSE}
heartKnn <- dplyr:: select(heart, MaxHRNorm, ExerciseAngina, HeartDisease)
heartKnn$ExerciseAngina <- as.factor(heartKnn$ExerciseAngina)
str(heartKnn)
```
# Stratified splitting for training and testing sets:

```{r}
heart0<-heartKnn%>%
  filter(HeartDisease==0)
dim(heart0)

heart1<-heartKnn%>%
  filter(HeartDisease==1)
dim(heart1)

## SAMPLE INDECES
set.seed(100)
heart_sample0<-sample(1:410, 287)
heart_sample1<-sample(1:508, 356)

## TRAINING AND TESTING SETS
trainStrat<-rbind(heart0[heart_sample0, ],
                  heart1[heart_sample1, ])

testStrat<-rbind(heart0[-heart_sample0, ],
                  heart1[-heart_sample1, ])

## PROPORITON OF OUTCOME
mean(trainStrat$HeartDisease)
```


```{r}
mean(testStrat$HeartDisease)
```
Now that I have training and testing sets that are stratified and a numeric explanatory feature and can implement the KNN algorithm. The means for the testStrat$HeartDisease$ and trainStrat$HeartDisease$ are 0.001 different which is acceptable.

# K Nearest Neighbors (k=3):
```{r}
### Specify Arguments
trainFea<-trainStrat%>%
  dplyr:: select(-HeartDisease)

testFea<-testStrat%>%
  dplyr:: select(-HeartDisease)

trainOut<-trainStrat$HeartDisease
testOut<-testStrat$HeartDisease

set.seed(1234)
knn.heartPred=knn(train = trainFea,
             test = testFea,
             cl = trainOut,
             k=3)
```
# Confusion Matrix
```{r}
cmHeart<-table(knn.heartPred,testOut)
cmHeart
```
#Correct Rate
```{r}
mean(knn.heartPred==testOut)
```
#Error Rate
```{r}
1-mean(knn.heartPred==testOut)
```
29.8% error rate 
### False Positive Rate: 37/275 = 13.5%

### False Negatives: 45/275 = 16.4%

#Sensitivity 
```{r}
### Sensitivity = True Positive / (True Positive + False Negative)
### cm: 1=TN 2=FP 3=FN 4=TP

cmHeart[4]/(cmHeart[4] + cmHeart[3])
```
#Specificity 
```{r}
### Specificity = True Negative / (False Positive + True Negative)

cmHeart[1]/(cmHeart[2] + cmHeart[1])
```


#Grid Search for best "k":
```{r}
## Whats the best k
## Pick a neighborhood
set.seed(123)
error <- c()
for (i in 1:30){
  knnHeart<- knn(train = trainFea,
                test = testFea,
                cl = trainOut, 
                k = i)
  error[i] = 1- mean(knnHeart==testOut)
}

ggplot(data = data.frame(error), aes(x = 1:30, y = error)) +
  geom_line(color = "Blue")+
  xlab("Neighborhood Size")
```

```{r}
which.min(error)
```
## The best model will contain 14 neighbors.



# Fit the best model 
```{r}
set.seed(1234)
knn.heartPredFinal=knn(train = trainFea,
             test = testFea,
             cl = trainOut,
             k=14)
```
#Confusion Matrix for best model
```{r}
knnFinalCM<-table(knn.heartPredFinal,testOut)
knnFinalCM
```
#Correct rate
```{r}
knnFinalCR <- mean(knn.heartPredFinal==testOut)
knnFinalCR
```
75% Correct Rate - Increased from 70.2%

# Error rate
```{r}
1-mean(knn.heartPredFinal==testOut)
```
25% Error Rate - Decreased from 29.8%

### False Positive Rate: 25/275 = 9% (decreased from 13.5%)

### False Negative Rate: 44/275 = 16% (decreased from 16.4%)

### Sensitivity
```{r}
### Sensitivity = True Positive / (True Positive + False Negative)
### cm: 1=TN 2=FP 3=FN 4=TP

knnFinalCM[4]/(knnFinalCM[4] + knnFinalCM[3])
```
Increased from 0.703

### Specificity
```{r}
### Specificity = True Negative / (False Positive + True Negative)

knnFinalCM[1]/(knnFinalCM[2] + knnFinalCM[1])
```
Increased even more dramatically from 0.699

# Logistic Regression
```{r, message = FALSE}
library(caret)
library(recipes)
# Split the data into training and test set
set.seed(314)
caretSamp <- createDataPartition(heart$HeartDisease ,
                                        p = 0.7,
                                        list = FALSE)

## SPLIT TESTING AND TRAINING
trainLR  <- heart[caretSamp, ]
testLR <- heart[-caretSamp, ]
```

# Simple Logistic Regression
```{r}
modLR <- glm(HeartDisease ~ Cholesterol, data=trainLR, family="binomial")
summary(modLR)

slope <- modLR$coefficients[2]
exp(slope)
```
### Plot Model
```{r}
ggplot(data=trainLR, aes(x=Cholesterol, fill=factor(HeartDisease)))+
  geom_density(alpha=.5)

ggplot(data=trainLR, aes(x=Cholesterol, y=HeartDisease))+
  geom_point()+
  geom_line(aes(x = Cholesterol, y = modLR$fitted), color="blue")
```
#### My first model is using cholesterol as a predictor of heart disease. The intercept is 1.15 and after back-transforming, I get a slope for cholesterol of 0.995, meaning that for every 1 unit increase in cholesterol there is a .995 increase on the likelihood of the patient acquiring heart disease. Cholesterol does have a significant effect on heart disease in my training data set.

## Confusion matrix at 0.5 threshold:

```{r}
pred1R<-predict(modLR, newdata = testLR, type="response")
head(pred1R)

conf_mat<-data.frame(testHeartDisease=testLR$HeartDisease, predHeart=pred1R>.5)
table(conf_mat$predHeart, conf_mat$testHeartDisease)

mean(conf_mat$predHeart == conf_mat$testHeartDisease)
```
Correct rate of 50%

## Multiple Logistic Regression Model:
```{r}
modMulti<-glm(HeartDisease ~.,
          data = trainLR, family = "binomial")

summary(modMulti)
```

## Final model:
```{r}
lmfinal <- glm(HeartDisease ~ Age + Sex + ChestPainType + Cholesterol + FastingBS + ExerciseAngina + Oldpeak + ST_Slope, data = trainLR, family="binomial")

predfinal<-predict(lmfinal, newdata = testLR, type="response")
head(predfinal)

conf_mat_final<-data.frame(testHeartDisease=testLR$HeartDisease, predHeart=predfinal>.5)
mlrFinalCm <- table(conf_mat_final$predHeart, conf_mat_final$testHeartDisease)
mlrFinalCm

mlrFinalCR <- mean(conf_mat_final$predHeart == conf_mat_final$testHeartDisease)
mlrFinalCR
```
88% Correct Rate.

# Trees
The outcome variable HeartDisease has to be encoded as a factor.
```{r}
heart$HeartDisease <- as.factor(heart$HeartDisease)
str(heart)
```
## Splitting into Training and Testing
```{r}
library(caret)
## Split the data into training and test set
set.seed(3)
caretSamp <- createDataPartition(heart$HeartDisease,
                                        p = 0.7,
                                        list = FALSE)

train <- heart[caretSamp, ]
test<- heart[-caretSamp, ]
```
## Fitting Classification Tree and observing patterns:
```{r}
set.seed(3)
library(rpart)

classTree<- rpart(HeartDisease ~., data = train, method = "class")

## Plot Tree
library(rpart.plot)
rpart.plot(classTree)

### Plot CP
plotcp(classTree)

printcp(classTree)


## Best CP
minCP<-classTree$cptable[which.min(classTree$cptable[,"xerror"]),"CP"]
```
It initially separates the data by the variable ST_Slope, which is the ST segment shift that is measured by an increase in exercise. It has been found to be the biggest indicator or coronary artery disease. It seems to be the strongest indicator of heart disease. It then separates into many other variables, and though I can explain each and every one, there are many individual cases, it does seem that chest pain type is a re-occuring indicator which does hint to my original research question of which types of chest pain are the best indicators of heart disease.

# Finding best CP and replotting my tree:
```{r}
library(rpart.plot)

prune_classTree <- prune(classTree, cp = minCP)
rpart.plot(prune_classTree)
```
#Confusion Matrix & calculating correct rate:
```{r}
predTree1<-predict(prune_classTree, test, type = "class")

## Confusion Matrix
cmTree1<-table(test$HeartDisease, predTree1)
cmTree1

## Correct Rate
mean(test$HeartDisease == predTree1)
```
80% correct rate.

#Tree Agreggation Using Bagging:
```{r}
library(tidyverse)

### BAG
set.seed(3)
caretBag <- train(HeartDisease ~.,
               data = train,
               method = "treebag",
               trControl = trainControl("cv", number = 10),
               importance = TRUE
)

predCaretBag <- caretBag %>% predict(test)
```
The number of features is equal to the parameters considered for each split.

```{r}
caretBag$finalModel
```
The bagging used 25 samples.

# Variable Importance Plot:
```{r}
library(vip)

vip(caretBag)
```
As my previous tree diagrams have shown, the variable ST_Slope seemed to be one of the most important, followed by Oldpeak and ExcerciseAngina.

#Confusion Matrix & correct rate for aggregated model:
```{r}
## Confusion Matrix
treeFinalCm <- table(predCaretBag, test$HeartDisease)
treeFinalCm

## Correct Rate
treeFinalCR <- mean(predCaretBag == test$HeartDisease)
treeFinalCR
```
84% Correct Rate.

# Compare

Confusion Matrix of Final KNN Model:
```{r}
knnFinalCM
knnFinalCR
```

Confusion Matrix of Final MLR Model:
```{r}
mlrFinalCm
mlrFinalCR
```

Confusion Matrix of Final Tree Model:
```{r}
treeFinalCm
treeFinalCR
```
# Results Table
```{r}
model_df <- data.frame(
  "Model Name" = c("KNN MODEL (k = 14)", "MLR MODEL (backwards selection)", "TREE MODEL (bagging)"),
  "Correct Rate" = c("75%", "88.7%", "84%"), 
  "False Positives" = c("25", "14", "28"),
  "False Negatives" = c("44", "17", "16")
)

# Print the data frame as a table
print(model_df)
```
## Discussion section:

Interpreting these results I can see that multiple logistic regression had the best correct rate on the testing data followed by decision tree aggregation using bagging, and then finally the KNN model after a grid search for the best neighborhood. Each method has its own pros and cons for example:

### KNN:

Pros:

- Between all of my models is the simplest to understand to the widest audience which could be best if you are attempting to explain to someone why they are predicted to have heart disease.

Cons:

- The correct rate was the smallest at 75%, also the number of false negatives was LARGEST at 44 and when diagnosing heart disease I want to limit false negatives so someone with heart disease does not go untreated or unaware.

### MLR Backwards Selection:

Pros:

- The highest correct rate at 88.7% which in turn also meant fewer false negatives.

Cons:

- The model still favored false negatives rather than false positives.

### Decision Tree Aggregation using Bagging:

Pros:

- A very high correct rate not far off of the multiple logistic regression model

- FEWER false negatives and the model favored false positives over false negatives!

Cons:

- The method of tree aggregation can be black-boxy and could be very hard to explain to some people when trying to understand why they are predicted to have or not have heart disease.

## Conclusion:

The model that seems to perform best for us considering the context of the data is the Tree Model using Bagging I do sacrifice 4.7% accuracy however limiting false negatives was a principal part of my project and being able to limit those errors are huge even to the point of possibly saving a life by catching heart disease in someone that is able to make changes in their lifestyle and become healthier.


# Conclusions:
  1. While it is not a professional diagnosis the models can give a person insights on health.
  2. My models are only as accurate as the diagnosis that doctors made in our     data. 
  3.Some of my models were more interpretable than others, which is important     when explaining to a person why they might be at risk for heart disease (could    be important to sacrifice some accuracy ex: an LDA model would be confusing for     a person with no DS background)

# Future Directions:

Including more data from around the world and different doctors could help make our models more accurate, also attempting to add more features that are better indicators of CVD.

Trying to understand how to continuously minimize false negatives for patients that are told they do not have heart disease but in reality they do.

Increase Interpretability! This is arguably the most important future direction as in healthcare it is important to patient to understand what conclusions are being made.


Citations: 
https://www.who.int/health-topics/cardiovascular-diseases#tab=tab_1
fedesoriano. (September 2021). Heart Failure Prediction Dataset. Retrieved 09/30/23 from https://www.kaggle.com/fedesoriano/heart-failure-prediction.
https://www.heart.org/en/health-topics/heart-attack/angina-chest-pain 

